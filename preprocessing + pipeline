import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression  # example model (can be changed)

# 1. Load data
df = pd.read_csv("Cardiovascular Diseases Risk Prediction Dataset export 2025-11-06 01-10-59.csv")

# 2. Target and features
y = df['Heart_Disease'].map({'Yes': 1, 'No': 0})   # convert to 0/1
X = df.drop('Heart_Disease', axis=1)

# 3. Feature groups
categorical_cols = [
    'General_Health', 'Checkup', 'Exercise', 'Skin_Cancer', 'Other_Cancer',
    'Depression', 'Diabetes', 'Arthritis', 'Sex', 'Age_Category',
    'Smoking_History'
]

numeric_cols = [
    'Height_(cm)', 'Weight_(kg)', 'BMI',
    'Alcohol_Consumption', 'Fruit_Consumption',
    'Green_Vegetables_Consumption', 'FriedPotato_Consumption'
]

# 4. Trainâ€“test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,        # 20% test
    random_state=42,      # reproducible
    stratify=y            # keep class balance
)

# 5. Preprocess: transformers for numeric + categorical
numeric_transformer = Pipeline(steps=[
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("onehot", OneHotEncoder(handle_unknown="ignore", drop=None))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_cols),
        ("cat", categorical_transformer, categorical_cols),
    ]
)

# 6. Build full pipeline with a model (example: Logistic Regression)
clf = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("model", LogisticRegression(max_iter=1000))
])

# 7. Fit the pipeline
clf.fit(X_train, y_train)

# 8. Evaluate simple accuracy (just to check everything works)
train_score = clf.score(X_train, y_train)
test_score = clf.score(X_test, y_test)

print(f"Train accuracy: {train_score:.3f}")
print(f"Test accuracy:  {test_score:.3f}")
