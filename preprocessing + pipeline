# 1. These lines import all the tools needed for the machine-learning workflow:
pandas → for loading and handling the dataset
train_test_split → for splitting data into training and test sets
OneHotEncoder & StandardScaler → for preprocessing categorical and numeric features
ColumnTransformer → to apply different preprocessing to different column groups
Pipeline → to combine preprocessing and the model into one workflow
LogisticRegression → the classification model used to predict heart disease


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression  # example model (can be changed)

# 2. Load data - This command reads the cardiovascular CSV file and stores it as a Pandas DataFrame (df), 
     which serves as the main dataset for analysis and model training.
df = pd.read_csv("Cardiovascular Diseases Risk Prediction Dataset export 2025-11-06 01-10-59.csv")

# 3. Target and features - The target column Heart_Disease is converted from text (“Yes/No”) into numerical binary values (1/0) 
     and stored as y for classification. All other columns are kept as input features in X by removing the target from the dataset. 
     y = df['Heart_Disease'].map({'Yes': 1, 'No': 0}) 
     X = df.drop('Heart_Disease', axis=1)

# 4. Feature groups - This creates a list of all categorical feature names in the dataset—columns that contain text or category-based 
     values (such as health status, medical history, and demographic information). These features will later be processed with One-Hot 
     Encoding because machine-learning models require numeric input.

categorical_cols = [
    'General_Health', 'Checkup', 'Exercise', 'Skin_Cancer', 'Other_Cancer',
    'Depression', 'Diabetes', 'Arthritis', 'Sex', 'Age_Category',
    'Smoking_History'
]

numeric_cols = [
    'Height_(cm)', 'Weight_(kg)', 'BMI',
    'Alcohol_Consumption', 'Fruit_Consumption',
    'Green_Vegetables_Consumption', 'FriedPotato_Consumption'
]

# 5. Train–test split - This splits the data into training and testing sets.
     80% of the data is used to train the model (X_train, y_train).
     20% is reserved for evaluating it (X_test, y_test).


X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,        # 20% test
    random_state=42,      # reproducible
    stratify=y            # keep class balance
)

# 6. Preprocess: transformers for numeric + categorical. This section sets up preprocessing: numeric features get scaled, 
     categorical features get one-hot encoded, and ColumnTransformer combines both so each feature is transformed correctly 
     before training.

numeric_transformer = Pipeline(steps=[
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("onehot", OneHotEncoder(handle_unknown="ignore", drop=None))
])

preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_cols),
        ("cat", categorical_transformer, categorical_cols),
    ]
)

# 7. Build full pipeline with a model (example: Logistic Regression)
    This creates a full machine-learning pipeline where the preprocessing steps (scaling + encoding) 
     and the Logistic Regression model are combined into one object (clf).
     When clf is trained, it automatically preprocesses the data and then fits the model.
clf = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("model", LogisticRegression(max_iter=1000))
])

# 8. Fit the pipeline
     This trains the entire pipeline (clf) using the training data.
     It first applies preprocessing, then fits the Logistic Regression model on the processed features.

clf.fit(X_train, y_train)

# 9. Evaluate simple accuracy (just to check everything works)
     These lines calculate how accurate the model is on both the training set and the test set.
    clf.score() returns the percentage of correct predictions. Finally, both accuracy scores are pri

train_score = clf.score(X_train, y_train)
test_score = clf.score(X_test, y_test)

print(f"Train accuracy: {train_score:.3f}")
print(f"Test accuracy:  {test_score:.3f}")
